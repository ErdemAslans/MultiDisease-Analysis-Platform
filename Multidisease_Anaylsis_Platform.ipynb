{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPtksvGI1GRyjOGAiOiElFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ce766345e0949d395a12e0072ecf1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_720f86a1dd7c47c8a8dae450d4d20564",
              "IPY_MODEL_a5eb842676a941cf897d51b77873975e",
              "IPY_MODEL_97bfe84a90354dc3b81c805dcf9de72c"
            ],
            "layout": "IPY_MODEL_292b2897b6484a35a89b423a4c9c8a55"
          }
        },
        "720f86a1dd7c47c8a8dae450d4d20564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c47c15b22d749cfb3b0eff10db8c432",
            "placeholder": "​",
            "style": "IPY_MODEL_dcde3d53e0d14231bedec708b54364a4",
            "value": "model.safetensors: 100%"
          }
        },
        "a5eb842676a941cf897d51b77873975e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95a9ccb6cd7847e1b6292811428dbe1f",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05090853541644ee86a7cd3b183afae4",
            "value": 346284714
          }
        },
        "97bfe84a90354dc3b81c805dcf9de72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_809020d3011c447895df94d93e1cf861",
            "placeholder": "​",
            "style": "IPY_MODEL_1f82e271144b40e6be80e6e65d9b5c3d",
            "value": " 346M/346M [00:01&lt;00:00, 231MB/s]"
          }
        },
        "292b2897b6484a35a89b423a4c9c8a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c47c15b22d749cfb3b0eff10db8c432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcde3d53e0d14231bedec708b54364a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95a9ccb6cd7847e1b6292811428dbe1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05090853541644ee86a7cd3b183afae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "809020d3011c447895df94d93e1cf861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f82e271144b40e6be80e6e65d9b5c3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErdemAslans/MultiDisease-Analysis-Platform/blob/main/Multidisease_Anaylsis_Platform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install  segmentation_models_pytorch\n",
        "!pip install monai\n",
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gweJrvNzmN4m",
        "outputId": "1346382f-92f5-4ceb-e3cd-46084b0206da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.4.0\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.26.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.7->timm) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E9uHFSmmdhc",
        "outputId": "fbf302db-b89f-416d-fee4-79de45689aed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (11.0.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_KczuLJmexi",
        "outputId": "abbfcdd0-a498-488e-8855-b8aca0f95284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/4.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bm3d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-J3BdTKmgsa",
        "outputId": "61ff63bf-6679-4475-e6c6-a367f1504ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bm3d\n",
            "  Downloading bm3d-4.0.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting bm4d>=4.2.5 (from bm3d)\n",
            "  Downloading bm4d-4.2.5-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bm4d>=4.2.5->bm3d) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from bm4d>=4.2.5->bm3d) (1.13.1)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from bm4d>=4.2.5->bm3d) (1.8.0)\n",
            "Downloading bm3d-4.0.3-py3-none-any.whl (10 kB)\n",
            "Downloading bm4d-4.2.5-py3-none-any.whl (862 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/862.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m860.2/862.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.0/862.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bm4d, bm3d\n",
            "Successfully installed bm3d-4.0.3 bm4d-4.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9hO4B52whFe",
        "outputId": "ce4303bb-b12b-47ab-9199-c0747c7600f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.5.1 (from gradio)\n",
            "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
            "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.1->gradio)\n",
            "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.8.0-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.4.0 gradio-5.8.0 gradio-client-1.5.1 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.19 ruff-0.8.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.32.1 websockets-14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afzI7YTaG2On",
        "outputId": "c580b203-d2b4-473c-f2c1-789440182193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0ce766345e0949d395a12e0072ecf1c6",
            "720f86a1dd7c47c8a8dae450d4d20564",
            "a5eb842676a941cf897d51b77873975e",
            "97bfe84a90354dc3b81c805dcf9de72c",
            "292b2897b6484a35a89b423a4c9c8a55",
            "2c47c15b22d749cfb3b0eff10db8c432",
            "dcde3d53e0d14231bedec708b54364a4",
            "95a9ccb6cd7847e1b6292811428dbe1f",
            "05090853541644ee86a7cd3b183afae4",
            "809020d3011c447895df94d93e1cf861",
            "1f82e271144b40e6be80e6e65d9b5c3d"
          ]
        },
        "id": "Yiv4QKYve0HY",
        "outputId": "2db38bed-56dd-4a83-c87c-dad79a339d2a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ce766345e0949d395a12e0072ecf1c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-f8311998da98>:117: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weight_path, map_location=device)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5911d3788e3d3fcb04.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5911d3788e3d3fcb04.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 624, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 323, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 2043, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1590, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 865, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-7-f8311998da98>\", line 248, in on_run\n",
            "    img_slice, pred_mask = gradio_process(image_file, mask_file, view, slice_idx)\n",
            "  File \"<ipython-input-7-f8311998da98>\", line 211, in gradio_process\n",
            "    image_nii = nib.load(image_file.name)\n",
            "AttributeError: 'NoneType' object has no attribute 'name'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gradio as gr\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.transform import resize\n",
        "from skimage import exposure\n",
        "import pywt\n",
        "from skimage.restoration import denoise_tv_chambolle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import timm\n",
        "\n",
        "# ------------------ Model Tanımı ------------------ #\n",
        "class CBAMBlock(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(CBAMBlock, self).__init__()\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(channels, channels // reduction, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels // reduction, channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.Conv2d(2, 1, kernel_size=7, padding=3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Kanal dikkat\n",
        "        ca = self.channel_attention(x)\n",
        "        x = x * ca\n",
        "        # Uzamsal dikkat\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        sa = torch.cat([avg_out, max_out], dim=1)\n",
        "        sa = self.spatial_attention(sa)\n",
        "        x = x * sa\n",
        "        return x\n",
        "\n",
        "class MultiScaleFeatureFusion(nn.Module):\n",
        "    def __init__(self, embed_dim, num_classes=1, dropout_rate=0.1):\n",
        "        super(MultiScaleFeatureFusion, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(embed_dim, embed_dim // 2, kernel_size=3, padding=1)\n",
        "        self.conv_pred = nn.Conv2d(embed_dim // 2, num_classes, kernel_size=1)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "        nn.init.kaiming_normal_(self.conv1.weight)\n",
        "        nn.init.kaiming_normal_(self.conv2.weight)\n",
        "        nn.init.kaiming_normal_(self.conv3.weight)\n",
        "        nn.init.kaiming_normal_(self.conv_pred.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = F.interpolate(self.conv1(x), size=(x.shape[2], x.shape[3]), mode='bilinear', align_corners=False)\n",
        "        x2 = self.conv2(x)\n",
        "        x3 = F.interpolate(self.conv3(x), size=(x.shape[2], x.shape[3]), mode='bilinear', align_corners=False)\n",
        "        fused = x1 + x2 + x3\n",
        "        fused = self.dropout(fused)\n",
        "        output = self.conv_pred(fused)\n",
        "        return output\n",
        "\n",
        "class ViTFeatureExtractor(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2):\n",
        "        super(ViTFeatureExtractor, self).__init__()\n",
        "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, drop_rate=dropout_rate, drop_path_rate=0.2)\n",
        "        self.vit.head = nn.Identity()\n",
        "        self.embed_dim = self.vit.embed_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.vit.forward_features(x)\n",
        "        return x\n",
        "\n",
        "class SegFormerDecoderWithAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_classes=1, patch_size=16, dropout_rate=0.4):\n",
        "        super(SegFormerDecoderWithAttention, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches_side = 224 // self.patch_size\n",
        "        self.linear_fuse = nn.Linear(embed_dim, embed_dim)\n",
        "        self.conv_pred = nn.Conv2d(embed_dim, num_classes, kernel_size=1)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.cbam = CBAMBlock(embed_dim)\n",
        "        self.multi_scale_fusion = MultiScaleFeatureFusion(embed_dim, num_classes, dropout_rate)\n",
        "        nn.init.kaiming_normal_(self.linear_fuse.weight)\n",
        "        nn.init.kaiming_normal_(self.conv_pred.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        x = x[:, 1:, :]\n",
        "        x = self.linear_fuse(x)\n",
        "        x = x.transpose(1, 2).contiguous().view(B, C, self.num_patches_side, self.num_patches_side)\n",
        "        x = F.interpolate(x, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "        x = self.cbam(x)\n",
        "        x = self.multi_scale_fusion(x)\n",
        "        return x\n",
        "\n",
        "class ViT_SegFormer_Model(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.2):\n",
        "        super(ViT_SegFormer_Model, self).__init__()\n",
        "        self.vit = ViTFeatureExtractor(dropout_rate)\n",
        "        self.decoder = SegFormerDecoderWithAttention(embed_dim=self.vit.embed_dim, dropout_rate=dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.vit(x)\n",
        "        output = self.decoder(features)\n",
        "        return output\n",
        "\n",
        "# Cihaz seçimi (GPU veya CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Modeli yükleme\n",
        "model = ViT_SegFormer_Model(dropout_rate=0.2).to(device)\n",
        "weight_path = \"/content/drive/MyDrive/Tümör/best_model.pth\"  # Kendi ağırlık dosyanızın yolunu ekleyin\n",
        "state_dict = torch.load(weight_path, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "# ------------------ Ön İşleme Fonksiyonları ------------------ #\n",
        "def enhance_contrast(image, clip_limit=0.6, tile_grid_size=(32,32), gamma=0.3):\n",
        "    min_val = np.min(image)\n",
        "    max_val = np.max(image)\n",
        "    if max_val - min_val == 0:\n",
        "        image = np.zeros_like(image)\n",
        "    else:\n",
        "        image = (image - min_val) / (max_val - min_val)  # [0, 1]\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "    image = clahe.apply((image * 255).astype(np.uint8)) / 255.0\n",
        "\n",
        "    inv_gamma = 1.0 / gamma\n",
        "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
        "    image = cv2.LUT((image * 255).astype(np.uint8), table).astype(np.float32) / 255\n",
        "\n",
        "    laplacian = cv2.Laplacian(image.astype(np.float64), cv2.CV_64F)\n",
        "    laplacian = np.clip(laplacian, 0, 1)\n",
        "    laplacian_weight = 0.33\n",
        "    enhanced_image = image + laplacian_weight * laplacian\n",
        "    enhanced_image = np.clip(enhanced_image, 0, 1)\n",
        "    return enhanced_image\n",
        "\n",
        "def apply_nlm_denoising(image):\n",
        "    denoised_image = cv2.fastNlMeansDenoising(np.uint8(image * 255), None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
        "    denoised_image = denoised_image.astype(np.float32) / 255.0\n",
        "    return denoised_image\n",
        "\n",
        "def apply_wavelet_denoising(image):\n",
        "    coeffs = pywt.wavedec2(image, 'haar', level=2)\n",
        "    coeffs = list(coeffs)\n",
        "    coeffs[1:] = [tuple(pywt.threshold(c, value=0.1, mode='soft') for c in level) for level in coeffs[1:]]\n",
        "    denoised_image = pywt.waverec2(coeffs, 'haar')\n",
        "    if denoised_image.shape != image.shape:\n",
        "        denoised_image = resize(denoised_image, image.shape, mode='reflect', anti_aliasing=True)\n",
        "    return denoised_image\n",
        "\n",
        "def apply_total_variation_denoising(image):\n",
        "    denoised_image = denoise_tv_chambolle(image, weight=0.1)\n",
        "    return denoised_image\n",
        "\n",
        "def process_single_nii(image_nii, mask_nii, view, slice_idx, target_size=(224,224)):\n",
        "    img = image_nii.get_fdata()\n",
        "    if mask_nii is not None:\n",
        "        mask = mask_nii.get_fdata()\n",
        "    else:\n",
        "        mask = np.zeros_like(img)\n",
        "\n",
        "    # Görüntü dilimleme\n",
        "    if view == 'sagittal':\n",
        "        max_slices = img.shape[0]\n",
        "        img_slice = img[slice_idx, :, :] if slice_idx < max_slices else img[max_slices//2,:,:]\n",
        "        mask_slice = mask[slice_idx, :, :] if slice_idx < max_slices else mask[max_slices//2,:,:]\n",
        "    elif view == 'coronal':\n",
        "        max_slices = img.shape[1]\n",
        "        img_slice = img[:, slice_idx, :] if slice_idx < max_slices else img[:, max_slices//2,:]\n",
        "        mask_slice = mask[:, slice_idx, :] if slice_idx < max_slices else mask[:, max_slices//2,:]\n",
        "    elif view == 'axial':\n",
        "        max_slices = img.shape[2]\n",
        "        img_slice = img[:, :, slice_idx] if slice_idx < max_slices else img[:,:,max_slices//2]\n",
        "        mask_slice = mask[:, :, slice_idx] if slice_idx < max_slices else mask[:,:,max_slices//2]\n",
        "\n",
        "    # Resize\n",
        "    img_slice = resize(img_slice, target_size, mode='reflect', anti_aliasing=True)\n",
        "    mask_slice = resize(\n",
        "        mask_slice, target_size, mode='reflect', anti_aliasing=False,\n",
        "        order=0, preserve_range=True\n",
        "    )\n",
        "\n",
        "    # İşlemler\n",
        "    img_slice = enhance_contrast(img_slice)\n",
        "    img_slice = apply_nlm_denoising(img_slice)\n",
        "    img_slice = apply_wavelet_denoising(img_slice)\n",
        "    img_slice = apply_total_variation_denoising(img_slice)\n",
        "\n",
        "    # Maskeyi binarize et\n",
        "    mask_slice = (mask_slice > 0.05).astype(np.float32)\n",
        "\n",
        "    # Maskeye göre parlaklık ayarlama\n",
        "    highlight_factor = 1.8\n",
        "    darken_factor = 0.8\n",
        "    img_slice_masked = img_slice * mask_slice * highlight_factor\n",
        "    img_slice_non_masked = img_slice * (1 - mask_slice) * darken_factor\n",
        "    img_slice = img_slice_masked + img_slice_non_masked\n",
        "    img_slice = np.clip(img_slice, 0, 1).astype(np.float32)\n",
        "\n",
        "    return img_slice, mask_slice\n",
        "\n",
        "def gradio_process(image_file, mask_file, view, slice_idx):\n",
        "    # NIfTI dosyalarını oku\n",
        "    image_nii = nib.load(image_file.name)\n",
        "    mask_nii = nib.load(mask_file.name) if mask_file is not None else None\n",
        "\n",
        "    # İşlenmiş görüntü ve maske\n",
        "    img_slice, mask_slice = process_single_nii(image_nii, mask_nii, view, slice_idx, target_size=(224,224))\n",
        "\n",
        "    # Modelin girdi formatına uygun dönüştürme\n",
        "    # Model 3 kanallı girdi beklediği varsayılarak tek kanallı görüntüyü 3 kanal haline getiriyoruz:\n",
        "    img_tensor = torch.from_numpy(img_slice).unsqueeze(0).unsqueeze(0)  # (1, 1, H, W)\n",
        "    img_tensor = img_tensor.repeat(1, 3, 1, 1) # (1, 3, 224, 224)\n",
        "    img_tensor = img_tensor.to(device)\n",
        "\n",
        "    # Model tahmini\n",
        "    with torch.no_grad():\n",
        "        logits = model(img_tensor)    # (1, 1, 224, 224)\n",
        "        pred_prob = torch.sigmoid(logits)\n",
        "        pred_mask = (pred_prob > 0.5).float()\n",
        "\n",
        "    pred_mask_np = pred_mask.cpu().squeeze().numpy()  # (224, 224) boyutunda\n",
        "\n",
        "    # Görüntü ve modelin tahmini maskeyi döndür\n",
        "    return (img_slice, pred_mask_np)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Tek NIfTI Dosyası Üzerinde Ön İşleme, Model ile Segmentasyon ve Görselleştirme\")\n",
        "    with gr.Row():\n",
        "        image_input = gr.File(label=\"NIfTI Görüntü Dosyası (.nii veya .nii.gz)\")\n",
        "        mask_input = gr.File(label=\"Maske Dosyası (Opsiyonel)\")\n",
        "    view_choice = gr.Dropdown(choices=[\"sagittal\", \"coronal\", \"axial\"], value=\"axial\", label=\"Görüntüleme Ekseni\")\n",
        "    slice_choice = gr.Slider(minimum=0, maximum=200, step=1, value=50, label=\"Dilim Numarası (seçilen eksene göre)\")\n",
        "\n",
        "    run_button = gr.Button(\"İşle ve Göster\")\n",
        "\n",
        "    output_image = gr.Image(label=\"İşlenmiş Görüntü\")\n",
        "    output_mask = gr.Image(label=\"Model Tahmin Maskesi\")\n",
        "\n",
        "    def on_run(image_file, mask_file, view, slice_idx):\n",
        "        img_slice, pred_mask = gradio_process(image_file, mask_file, view, slice_idx)\n",
        "        return img_slice, pred_mask\n",
        "\n",
        "    run_button.click(fn=on_run, inputs=[image_input, mask_input, view_choice, slice_choice], outputs=[output_image, output_mask])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    }
  ]
}